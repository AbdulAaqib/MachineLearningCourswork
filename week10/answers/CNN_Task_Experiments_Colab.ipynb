{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Force compatible package versions for Colab + TF 2.19\n",
        "# - numpy pinned to <2.2\n",
        "# - pandas pinned to 2.2.2 (matches google-colab requirement)\n",
        "# - scipy pinned to a version compatible with numpy\n",
        "!pip -q install \"numpy==2.0.2\" \"pandas==2.2.2\" \"matplotlib==3.9.0\" \"scipy==1.13.1\"\n",
        "\n",
        "# IMPORTANT: Restart runtime so the pinned versions are actually used.\n",
        "import os; os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN Task Experiments (Colab-ready)\n",
        "\n",
        "This notebook runs the experiments requested in Week 10 using a simple CNN on CIFAR-10:\n",
        "\n",
        "- Kernels 3×3 with epochs 10, 20, 50\n",
        "- Kernels 5×5 with epochs 10, 20\n",
        "\n",
        "It produces:\n",
        "- Accuracy plots (PNG) for each run\n",
        "- Summary CSV and JSON files for each kernel size\n",
        "\n",
        "How to use:\n",
        "1. Runtime → Change runtime type → Select GPU (recommended)\n",
        "2. Run the cells from top to bottom\n",
        "3. Download the generated files from /content/results (or zip them in the last cell)\n",
        "4. Place them into week10/answers and tell me; I will append the exact numbers to answers.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep Colab’s TF-compatible versions (avoid upgrading numpy/pandas)\n",
        "!pip -q install --upgrade --no-deps \"matplotlib==3.9.0\"\n",
        "\n",
        "import os, time, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, models, layers\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print('TensorFlow:', tf.__version__)\n",
        "print('GPU available?', tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(kernel_size=(3, 3)):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, kernel_size, activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, kernel_size, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, kernel_size, activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10))  # logits\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def load_data():\n",
        "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "    train_images = train_images.astype('float32') / 255.0\n",
        "    test_images  = test_images.astype('float32') / 255.0\n",
        "    train_labels = train_labels.reshape(-1)\n",
        "    test_labels  = test_labels.reshape(-1)\n",
        "    return (train_images, train_labels), (test_images, test_labels)\n",
        "\n",
        "os.makedirs('/content/results', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(epochs, kernel_size, out_dir):\n",
        "    (train_images, train_labels), (test_images, test_labels) = load_data()\n",
        "    model = build_model(kernel_size=kernel_size)\n",
        "    start = time.time()\n",
        "    history = model.fit(\n",
        "        train_images, train_labels,\n",
        "        epochs=epochs,\n",
        "        batch_size=128,\n",
        "        validation_data=(test_images, test_labels),\n",
        "        verbose=1\n",
        "    )\n",
        "    duration = time.time() - start\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "    # Accuracy learning curve\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(f'Accuracy (epochs={epochs}, kernel={kernel_size})\\nTest acc={test_acc:.4f}, time={duration/60:.1f} min')\n",
        "    plt.legend()\n",
        "    acc_plot_path = os.path.join(out_dir, f\"cnn_task_acc_epochs_{epochs}_kernel_{kernel_size[0]}x{kernel_size[1]}.png\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(acc_plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Loss learning curve\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history.history['loss'], label='train_loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Loss (epochs={epochs}, kernel={kernel_size})')\n",
        "    plt.legend()\n",
        "    loss_plot_path = os.path.join(out_dir, f\"cnn_task_loss_epochs_{epochs}_kernel_{kernel_size[0]}x{kernel_size[1]}.png\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(loss_plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Confusion matrix on test set\n",
        "    logits = model.predict(test_images, batch_size=256, verbose=0)\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    cm = tf.math.confusion_matrix(test_labels, y_pred, num_classes=10).numpy()\n",
        "\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix (epochs={epochs}, kernel={kernel_size})')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(10)\n",
        "    plt.xticks(tick_marks, tick_marks)\n",
        "    plt.yticks(tick_marks, tick_marks)\n",
        "    thresh = cm.max() / 2.0\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                     ha='center', va='center',\n",
        "                     color='white' if cm[i, j] > thresh else 'black')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    cm_plot_path = os.path.join(out_dir, f\"cnn_task_cm_epochs_{epochs}_kernel_{kernel_size[0]}x{kernel_size[1]}.png\")\n",
        "    plt.savefig(cm_plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    return {\n",
        "        'epochs': int(epochs),\n",
        "        'kernel_size': f\"{kernel_size[0]}x{kernel_size[1]}\",\n",
        "        'test_acc': float(test_acc),\n",
        "        'test_loss': float(test_loss),\n",
        "        'duration_sec': float(duration),\n",
        "        'acc_plot': os.path.basename(acc_plot_path),\n",
        "        'loss_plot': os.path.basename(loss_plot_path),\n",
        "        'cm_plot': os.path.basename(cm_plot_path),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_battery(epochs_list, kernel_size, out_dir='/content/results'):\n",
        "    results = []\n",
        "    for e in epochs_list:\n",
        "        results.append(run_experiment(e, kernel_size, out_dir))\n",
        "    df = pd.DataFrame(results)\n",
        "    csv_path = os.path.join(out_dir, f\"cnn_task_results_kernel_{kernel_size[0]}x{kernel_size[1]}.csv\")\n",
        "    json_path = os.path.join(out_dir, f\"cnn_task_results_kernel_{kernel_size[0]}x{kernel_size[1]}.json\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    return df, csv_path, json_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tip: If training is slow on CPU, go to Runtime → Change runtime type → Hardware accelerator: GPU, then run the first cell (version pin) and restart automatically, then run all other cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3x3 kernels: 10, 20, 50 epochs\n",
        "df_3x3, csv_3x3, json_3x3 = run_battery([10, 20, 50], (3, 3), out_dir='/content/results')\n",
        "print('3x3 results:')\n",
        "display(df_3x3)\n",
        "print('Saved:', csv_3x3, json_3x3)\n",
        "\n",
        "# 5x5 kernels: 10, 20 epochs\n",
        "df_5x5, csv_5x5, json_5x5 = run_battery([10, 20], (5, 5), out_dir='/content/results')\n",
        "print('5x5 results:')\n",
        "display(df_5x5)\n",
        "print('Saved:', csv_5x5, json_5x5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zip all results for easy download\n",
        "import shutil\n",
        "shutil.make_archive('/content/cnn_task_results', 'zip', '/content/results')\n",
        "print('Zipped -> /content/cnn_task_results.zip')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
